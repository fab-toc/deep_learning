{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP vs CNN (bonus)\n",
    "\n",
    "In lab 3 we have defined an MLP classifier, and in the previous script we used a CNN classifier. A natural question is: how do they compare, and which one is the best? The goal of this exercise is to answer this question, in terms of number of parameters, training behavior, and accuracy on the test set.\n",
    "\n",
    "&nbsp; \n",
    "\n",
    "<center><a href=\"https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\">\n",
    "    <img src=\"https://miro.medium.com/max/700/1*1Cw9nKcdKV5YQun-e4F8gQ.png\"></a></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "# Define the data repository\n",
    "data_dir = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization function\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "train_data = datasets.FashionMNIST(data_dir, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(data_dir, train=False, download=True, transform=transforms.ToTensor())\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "train_data = Subset(train_data, torch.arange(500))\n",
    "test_data = Subset(test_data, torch.arange(50))\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 8\n",
    "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: write the MLP and CNN (with batch norm) classifiers modules (you can reuse your code for the past scripts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: write the training function.\n",
    "# No need to write 2 functions (one for MLP and one for CNN), you can use the same but be careful about image vectorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: write the evaluation function (again, no need to write 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters\n",
    "num_classes = 10\n",
    "num_epochs = 30\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "\n",
    "# MLP\n",
    "input_size_mlp = train_data[0][0][0].shape[0]*train_data[0][0][0].shape[1]\n",
    "hidden_size_mlp = 50\n",
    "\n",
    "# CNN\n",
    "num_channels1 = 16\n",
    "num_channels2 = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Instanciate, initialize and train the two models. Compute accuracy on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: compare the MLP and CNN models\n",
    "# - print the number of parameters of each model\n",
    "# - plot the training loss\n",
    "# - display the test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Q5**</span> Put these results in your report. Which one is the winner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
